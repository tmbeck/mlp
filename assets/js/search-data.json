{
  
    
        "post0": {
            "title": "The story so far",
            "content": "The Story so Far . Ok, so this all started around July 2020 when I decided to invest in my own education and learn more about what some of my team members were working on. One of them suggested fast.ai so I decided to give it a try. . At the time, the course v3 was in “production”. Since then, v4 has been released. . Setup . Being the hands on engineer that I am, I decided to build my own system for machine learning from spare parts around the house. I already have experience deploying jupyter for use by development teams and I am no stranger to Linux. The fast.ai Getting Started guide originally suggested using managed services such as Google Cloud or AWS, but it was straightforward enough to get something working that I’ve documented it below. . Note that this isn’t recommended by Jeremy in the video lesson, but I decided to do it to understand what is going on behind the scenes (and why pay AWS when I have the hardware and free solar energy). . Hardware . These are parts I had laying around the house. The key if you want GPU acceleration with pytorch is to have the right GPU; too old and your GPU won’t support the necessary GPU compute capabilities. Below is the harware I had on hand: . Intel i7-4770 | 32 GB of RAM | NVIDIA Corporation GM204 [GeForce GTX 970] (rev a1); GPU compute capability 5.2 | 1 TB SSD (actually an upgrade; spinning rust was unbearably slow due to the low number of random IOPS) | . Software . Linux is my preferred operating system in general for hacking, so I went with the recently released Ubuntu 20.04 LTS Server. . I’ve been using anaconda as my python distribution of choice for many years now, so I grabbed the python 3.8 x86_64 for Linux package. . I also grabbed docker.io. Nvidia has a solution for doing GPU compute that requires docker to be installed, as well. . Since fastai uses pytorch, and pytorch only support CPU or GPU via cudatoolkit, I needed the nvidia.ko kernel module, the necessary nvidia cuda toolkit libraries, and the right packages in a conda environment. . I installed nvidia-dkms-450 to provide nvidia drivers for my GTX 970. . Nvidia provides a CUDA toolkit 10.2 Ubuntu repo. Even though it says 18.04, it worked fine for me on 20.04. Just follow the instructions to install the cuda package. . You might also find the NVIDIA CUDA Installation Guide for Linux helpful for troubleshooting installation issues. . Reboot as needed. . Integration &amp; Test . Finally we can create a new conda environment, install the necessary packages, and verify pytorch can see and use the GPU. . Create a fastai conda environment with python 3.8 | $ conda create -n fastai python=3.8 $ conda activate fastai . Install fastai in conda, as per their Install Instructions. It might take a while for conda to determine which channel to get the packages from. | $ conda install -c fastai -c pytorch -c anaconda fastai gh anaconda $ conda install -c fastai -c pytorch -c anaconda fastai gh anaconda cudatoolkit=10.2 Collecting package metadata (current_repodata.json): done Solving environment: done ## Package Plan ## environment location: /home/tbeck/anaconda3 added / updated specs: - anaconda - cudatoolkit=10.2 - fastai - gh The following packages will be downloaded: package | build |-- ca-certificates-2020.7.22 | 0 132 KB anaconda certifi-2020.6.20 | py37_0 159 KB anaconda conda-4.8.4 | py37_0 3.0 MB anaconda cudatoolkit-10.2.89 | hfd86e86_1 540.0 MB anaconda gh-0.11.1 | 0 5.5 MB fastai openssl-1.1.1g | h7b6447c_0 3.8 MB anaconda Total: 552.5 MB The following NEW packages will be INSTALLED: gh fastai/linux-64::gh-0.11.1-0 The following packages will be SUPERSEDED by a higher-priority channel: ca-certificates pkgs/main --&gt; anaconda certifi pkgs/main --&gt; anaconda conda pkgs/main --&gt; anaconda cudatoolkit pkgs/main --&gt; anaconda openssl pkgs/main --&gt; anaconda Proceed ([y]/n)? . Once installed, you can quickly test that your GPU is seen and used from the command line like so: | $ python -c &#39;import torch; print(torch.cuda.get_device_name())&#39; GeForce GTX 970 $ python -c &#39;import torch; print(torch.rand(2,3).cuda())&#39; tensor([[0.3352, 0.0835, 0.5349], [0.3712, 0.2851, 0.8767]], device=&#39;cuda:0&#39;) . If you see your expected video card and a tensor returned, you’re all set. If you have multiple GPU’s installed, you may need to specify which one to use. Check out this stack overflow article on how to set the appropriate environment variables for the command line and for jupyter to work. . A note on updates . I’ve noticed that if you update conda using conda update --all, it will try to pull in the latest version of cudatoolkit, which as of this writing is cudatoolkit-11.0.221-h6bb024c_0. This is safe to do, but you will need to downgrade back to cudatoolkit-10.2. Below is an example. . Upgrading conda (only showing cudatoolkit for visbility - your output will differ) bash $ conda update –all … The following packages will be UPDATED: | cudatoolkit anaconda::cudatoolkit-10.2.89-hfd86e8~ –&gt; pkgs/main::cudatoolkit-11.0.221-h6bb024c_0 . 2. Downgrading cudatoolkit bash $ conda install pytorch torchvision cudatoolkit=10.2 -c pytorch ... added / updated specs: - cudatoolkit=10.2 The following packages will be downloaded: package | build |-- cudatoolkit-10.2.89 | hfd86e86_1 365.1 MB Total: 365.1 MB The following packages will be DOWNGRADED: cudatoolkit 11.0.221-h6bb024c_0 --&gt; 10.2.89-hfd86e86_1 . Troubleshooting | Note that trying to install cudatoolkit=10.2 alone might result in the error below, so be sure that pytorch and torchvision are included as above. . $ python -c &#39;import torch; print(torch.rand(2,3).cuda())&#39; Traceback (most recent call last): File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; File &quot;/home/tbeck/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/cuda/__init__.py&quot;, line 192, in _lazy_init _check_driver() File &quot;/home/tbeck/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/cuda/__init__.py&quot;, line 95, in _check_driver raise AssertionError(&quot;Torch not compiled with CUDA enabled&quot;) AssertionError: Torch not compiled with CUDA enabled . Preparing for class . There are two sets of notebooks for the class: . The fastbook, a guided set of notebooks with prose for following along in the videos: fastbook | The same notebooks as a study aid: course-v4 | . Please consider showing your support by buying the fastbook: Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD . I setup my own area for hacking: . $ mkdir ~/src $ cd ~/src &amp;&amp; git clone https://github.com/fastai/fastbook.git &amp;&amp; git clone https://github.com/fastai/course-v4.git . Now that CUDA is working and we have the code, I prefer fire up my jupyter notebook in a screen session. To do this I generated a https://jupyter-notebook.readthedocs.io/en/stable/config.html via jupyte notebook --generate-config and wrote it to ~/.jupyter/jupyte_notebook_config.py. Then I made it listen on 0.0.0.0 so I can reach it from my LAN (or anywhere in the world via wireguard!). . Now I just run screen, activate conda with conda activate fastai, and finally start jupyter with jupyter notebook. For tricks on using screen see this quickreference . If you prefer to use jupyter lab, you’ll need to conda install jupyterlab and run jupyter lab instead. .",
            "url": "https://blog.tbeck.io/linux/education/fastai/2020/09/05/the-story-so-far.html",
            "relUrl": "/linux/education/fastai/2020/09/05/the-story-so-far.html",
            "date": " • Sep 5, 2020"
        }
        
    
  
    
  
    
        ,"post2": {
            "title": "fastai v4: Lesson 1",
            "content": "Lesson 1 . Notes from fastai lesson 1. . Links . Lesson 1 Video | fastai Forum | . Notes . Discussed what’s needed to take this course (not much!). | Discussed history of AI and how deep neural networks came to be. Mostly news to me, 1/10. | Introduced Jupyter, ipywidgets, REPL. Mostly seen this before, 7/10. | Introduced ML (repeat, but still new, 4/10) take an input, process it, get an output. | Samuel’s terminology: take inputs &amp; weights into a model, generate results | Add feedback: measure performance of the results (a metric), then change weights. Rinse &amp; repeat. | Different weights to the model allows it to do a different task | Universal approximation theorem: theory that a neural network could solve any problem to any level of accuracy. | Need a way to update weights - SGD: stochastic gradient descent - to update the weights | . | Jargon | Keyword Description . Architecture | The “program” we are running. Often synonymous with model, but represents its functional form.. | . Parameters | The “weights” into the “program” | . Predictions | The output of our architecture, computed from independent variables which does not include labels | . Labels | The targets or dependent variables, assumed to be true for a given prediction. | . Loss | A metric of performance we measure our model by: how well did our prediction (computed from independent variables) match our labels (our dependent variables)? | . Model | The combination of the parameters and architecture that can act on inputs to generate a prediction. | . Inputs | The data on which the model acts to generate a prediction. No inputs (data) == No predictions! | . Action | The decision made from reasoning about a given prediction. | . From the loss, we can /update/ the weight for a given input, thus allowing our system to learn. . ML Limitations | A model can only be created from data | A model can only learn from patterns in the inputs | A model can only make a prediction - actions happen externally | . Labeled data is key and often missing - good part, bad part, etc. . It is important to note that a feedback loop can be created, resulting in a causal relationship where none existed before. Jeremy gave an example in lesson 1. This goes to ethics along ML and understanding inherent biases in your training dataset that you may not be aware of. . The fastai notebook | Intro to fastai. Discuss REPL, data sets, etc. . from fastai.vision.all import * . learner = cnn_learner(dls, resnet34, metrics=error_rate) . Here cnn_learner is a function that generates our model, dls is our dataset, resnet34 is our architecture, and error_rate is a loss function for feedback. . resnet34 is a predefined neural network trained on images that is free to use. 34 indicates it has 34 layers, more layers requires more GPU memory. . error_rate is computed on data not used in training, also known as a holdout set or validation set, to help avoid overfitting. Might need to increase the size of the holdout set to avoid overfitting. The ambiguiuty is actually important in model building, otherwise the model will only know how to recognize images it has seen before. . Other uses | segmentation: figuring out what every pixel in an image is (what label it corresponds to) . For a PWA, labels might be . trace, screw, via, component | . A larger training set might allow . trace, via, capacitor, resistor, inductor, transistor, integrated circuit, etc. | . Project idea: create an architecture for use in image segmentation that is trained on images of various PWAs (raspberry Pis, motherboards, etc.) to recognize features. . tabular data: fitting a model to predict salary based on a variety of parameters, predicting ratings a user might give a movie they haven’t seen based on previous ratings they have given (known as collaboration, used in recommendation engines) . Homework . Do the questionaire, run the notebooks, etc. .",
            "url": "https://blog.tbeck.io/education/fastai/2020/09/05/lesson-1.html",
            "relUrl": "/education/fastai/2020/09/05/lesson-1.html",
            "date": " • Sep 5, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": ". Timothy Beck I recieved a degree in Electrical Engineering from UCSD in 2007. I’ve worked most of my engineering career at Viasat, where I’ve enjoyed career mobility by being a test engineer, software engineer, and hardware engineer, later becoming a cross-functional leader of an engineering organization comprised of mechanical, hardware (including programmable logic), and software engineers. Much of my careeer has been focused on constructing what would now be considered a well-labeled datasets, as well as analysis tools for computing process capability metrics, support root cause analysis, providing insight into product performance, etc. . . Since learning more about data science and machine learning, I’ve begun exploring the intersection of ML and manufacturing, particularly how ML can accelerate manufacturing &amp; test processes. I feel passionately that this technology can be used to improve product design by providing greater context and understanding of manufacturing, test, and operational dataasets. . I first started diving into machine learning myself using the fast.ai v3 course, but switched to v4 of the course when it was recently released. In Lesson 3 of v4 of the course, Jeremy recommends to write about what you are learning. Once I saw fastpages1, I figured it was time to start writing. They had me once I found out I could convert jupyter notebooks to blog posts! . I created this site to help me document my journey, study, challenge myself, and show off what I’ve learned. . This website is powered by fastpages1. . All images are &copy; Tim Beck, all rights reserved. a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; &#8617;2 . |",
          "url": "https://blog.tbeck.io/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://blog.tbeck.io/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}