---
title: "fastai v4: Lesson 2"
description: "Notes from Lesson 2 of fastai v4"
author: "<a href='https://www.linkedin.com/in/tmbeck'>Tim Beck</a>"
toc: true
comments: false
keywords: fastai
categories: [education, fastai]
badges: true
layout: post
---
# Lesson 2

Notes from fastai lesson 2.

## Links

* [Lesson 2 Video](https://course.fast.ai/videos/?lesson=2)
* [fastai Forum](https://forums.fast.ai/)
* [Model Zoo](https://modelzoo.co/)
* [ONNX Models](https://github.com/onnx/models)

## Notes

Transfer learning: using an existing architecture to create a model trained on a particular data set

Error is one kind of metric, measuring "how well you're doing"
Loss is a measure of performance used to improve the parameters. "Are we learning (adjusting our parameters)?"

Model training

- Built a model from Bing API search results (grizzly vs black vs teddy bears)
- Used `DataBlock()` to create a dataset
- Used dataloaders to load the data into memory
- Used the `resnet18` architecture to train a model using the dataset, similar to lesson 1
- Exported the model via pickle to productionize it - model contains the architecture + new parameters + vocabulary (labels)
- Used the model to perform inference on images the model has not seen before
- Used `ImageClassifierCleaner()` to clean the dataset

Next lesson

- Deploying to binder, treating your model as if it's in production by uploading new images to it in "production"

## Jargon

|Jargon We Use (again)|Description|
|:---:|:---|
|Label|The data we're trying to predict (recall the diagram)|
|Architecture|A template of the model we are trying to fit. It represents the mathematical function we pass inputs & parameters to.|
|Model|An architecture with a specific set of parameters. The parameters may be created through training over one or more epochs.|
|Parameters|The values of the model that we can alter trough training.|
|Fit or Train|Updating the parameters such that the model is better able to predict our labels.|
|Pretrained model|A model with parameters adjusted via training, typically will be `fine_tune()`d, such as `resnet34`.|
|fine tune|Update a pretrained model for another task, such as making `resnet34` recognize cats or dogs.|
|epoch|One complete pass through the input data|
|metric|A measure of how good the model is to control training via SGD|
|validation set|A subset of our data we do not train our model with to measure its performance|
|training set|A subset of our data we train our model with that does not include any data from the validation set|
|overfitting|Training a model that results in memorization rather than generalization|
|cnn|A convolutional neural network, a type of NN suited for computer vision|

## Flash Cards:

* Architecture vs. Model?
    * A model includes an architecture with a specific set of parameters. These parameters allow the architecture to do something it wasn't originally designed to do.

## Where is Deep Learning good?

1. Computer Vision - detection & classification
2. Text - Classifiction & conversation (but not really)
3. Tabular - Effective on high cardinality datasets, e.g. part numbers and serial numbers
4. Recommendation Systems (Recsys, aka Collaborative Filtering), but note predictions <> recommendations - because you like to read science fiction, a model might predict you'll like Aasimov - but that might not be what you want from a recommendation engine e.g. if you're branching out to Romance.
4. Multi-modal - Combining the above, capition images, humans in the loop
5. Various other - NLP, protein

## Products in the wild

1. [Arsenal 2](https://www.kickstarter.com/projects/2092430307/arsenal-2/description), combining a camera with an AI platform
2. [Birdsy](https://www.kickstarter.com/projects/birdsy/birdsy-ai-records-and-ids-birds-and-wildlife-for-you), using computer vision to classify birds in real time

## Get Writing

This blog :)
