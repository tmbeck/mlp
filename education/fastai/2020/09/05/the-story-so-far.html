<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>The story so far | ML Development Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="The story so far" />
<meta name="author" content="<a href='https://www.linkedin.com/in/tmbeck'>Tim Beck</a>" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Review &amp; notes from the first two lessons of fastai v4." />
<meta property="og:description" content="Review &amp; notes from the first two lessons of fastai v4." />
<link rel="canonical" href="https://blog.tbeck.io/education/fastai/2020/09/05/the-story-so-far.html" />
<meta property="og:url" content="https://blog.tbeck.io/education/fastai/2020/09/05/the-story-so-far.html" />
<meta property="og:site_name" content="ML Development Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-05T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Review &amp; notes from the first two lessons of fastai v4.","url":"https://blog.tbeck.io/education/fastai/2020/09/05/the-story-so-far.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.tbeck.io/education/fastai/2020/09/05/the-story-so-far.html"},"headline":"The story so far","dateModified":"2020-09-05T00:00:00-05:00","datePublished":"2020-09-05T00:00:00-05:00","author":{"@type":"Person","name":"<a href='https://www.linkedin.com/in/tmbeck'>Tim Beck</a>"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://blog.tbeck.io/feed.xml" title="ML Development Blog" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css">

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">ML Development Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/links/">Useful Links</a><a class="page-link" href="/projects/">Projects</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">The story so far</h1><p class="page-description">Review & notes from the first two lessons of fastai v4.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-05T00:00:00-05:00" itemprop="datePublished">
        Sep 5, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name"><a href='https://www.linkedin.com/in/tmbeck'>Tim Beck</a></span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#education">education</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#fastai">fastai</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#the-story-so-far">The Story so Far</a>
<ul>
<li class="toc-entry toc-h2"><a href="#setup">Setup</a>
<ul>
<li class="toc-entry toc-h3"><a href="#hardware">Hardware</a></li>
<li class="toc-entry toc-h3"><a href="#software">Software</a></li>
<li class="toc-entry toc-h3"><a href="#integration--test">Integration &amp; Test</a></li>
<li class="toc-entry toc-h3"><a href="#a-note-on-updates">A note on updates</a>
<ul>
<li class="toc-entry toc-h4"><a href="#upgrading-conda-only-showing-cudatoolkit-for-visbility---your-output-will-differ">Upgrading conda (only showing cudatoolkit for visbility - your output will differ)</a></li>
<li class="toc-entry toc-h4"><a href="#downgrading-cudatoolkit">Downgrading cudatoolkit</a></li>
<li class="toc-entry toc-h4"><a href="#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#preparing-for-class">Preparing for class</a></li>
</ul>
</li>
</ul>
</li>
</ul><h1 id="the-story-so-far">
<a class="anchor" href="#the-story-so-far" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Story so Far</h1>

<p>Ok, so this all started around July 2020 when I decided to invest in my own education and learn more about what some of my team members were working on. One of them suggested <a href="https://fast.ai">fast.ai</a> so I decided to give it a try.</p>

<p>At the time, the course v3 was in “production”. Since then, v4 has been released.</p>

<h2 id="setup">
<a class="anchor" href="#setup" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setup</h2>

<p>Being the hands on engineer that I am, I decided to build my own system for machine learning from spare parts around the house. I already have experience deploying jupyter for use by development teams and I am no stranger to Linux. The fast.ai Getting Started guide originally suggested using managed services such as Google Cloud or AWS, but it was straightforward enough to get something working that I’ve documented it below.</p>

<p>Note that this isn’t recommended by Jeremy in the video lesson, but I decided to do it to understand what is going on behind the scenes (and why pay AWS when I have the hardware and free solar energy).</p>

<h3 id="hardware">
<a class="anchor" href="#hardware" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hardware</h3>

<p>These are parts I had laying around the house. The key if you want GPU acceleration with <code class="language-plaintext highlighter-rouge">pytorch</code> is to have the right GPU; too old and your GPU won’t support <a href="https://developer.nvidia.com/cuda-gpus">the necessary GPU compute capabilities</a>. Below is the harware I had on hand:</p>

<ul>
  <li>Intel i7-4770</li>
  <li>32 GB of RAM</li>
  <li>NVIDIA Corporation GM204 [GeForce GTX 970] (rev a1); GPU compute capability 5.2</li>
  <li>1 TB SSD (actually an upgrade; spinning rust was unbearably slow due to the low number of random IOPS)</li>
</ul>

<h3 id="software">
<a class="anchor" href="#software" aria-hidden="true"><span class="octicon octicon-link"></span></a>Software</h3>

<p>Linux is my preferred operating system in general for hacking, so I went with the recently released Ubuntu 20.04 LTS Server.</p>

<p>I’ve been using <a href="https://www.anaconda.com/products/individual">anaconda</a> as my python distribution of choice for many years now, so I grabbed the python 3.8 x86_64 for Linux package.</p>

<p>I also grabbed <a href="https://docs.docker.com/engine/install/ubuntu/">docker.io</a>. Nvidia has a solution for doing GPU compute that requires docker to be installed, as well.</p>

<p>Since fastai uses pytorch, and pytorch only support CPU or GPU via cudatoolkit, I needed the <code class="language-plaintext highlighter-rouge">nvidia.ko</code> kernel module, the necessary nvidia cuda toolkit libraries, and the right packages in a conda environment.</p>

<p>I installed <code class="language-plaintext highlighter-rouge">nvidia-dkms-450</code> to provide nvidia drivers for my GTX 970.</p>

<p><a href="https://developer.nvidia.com/cuda-10.2-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1804&amp;target_type=debnetwork">Nvidia provides a CUDA toolkit 10.2 Ubuntu repo</a>. Even though it says 18.04, it worked fine for me on 20.04. Just follow the instructions to install the <code class="language-plaintext highlighter-rouge">cuda</code> package.</p>

<p>You might also find the <a href="https://docs.nvidia.com/cuda/archive/10.2/cuda-installation-guide-linux/index.html">NVIDIA CUDA Installation Guide for Linux</a> helpful for troubleshooting installation issues.</p>

<p>Finally, to take advantage of the GPU you must install the GPU-accelerated version of <a href="https://pytorch.org/get-started/locally/">pytorch</a>. Only the conda instructions are needed since the system python isn’t used.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>conda <span class="nb">install </span>pytorch torchvision <span class="nv">cudatoolkit</span><span class="o">=</span>10.2 <span class="nt">-c</span> pytorch
</code></pre></div></div>

<p>Reboot as needed.</p>

<h3 id="integration--test">
<a class="anchor" href="#integration--test" aria-hidden="true"><span class="octicon octicon-link"></span></a>Integration &amp; Test</h3>

<p>Finally we can create a new conda environment, install the necessary packages, and verify pytorch can see and use the GPU.</p>

<ol>
  <li>
    <p>Create a fastai conda environment with python 3.8</p>

    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> <span class="nv">$ </span>conda create <span class="nt">-n</span> fastai <span class="nv">python</span><span class="o">=</span>3.8
 <span class="nv">$ </span>conda activate fastai
</code></pre></div>    </div>
  </li>
  <li>
    <p>Install fastai in conda, as per their <a href="https://docs.fast.ai/">Install Instructions</a>. It might take a while for <code class="language-plaintext highlighter-rouge">conda</code> to determine which channel to get the packages from.</p>

    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> <span class="nv">$ </span>conda <span class="nb">install</span> <span class="nt">-c</span> fastai <span class="nt">-c</span> pytorch <span class="nt">-c</span> anaconda fastai gh anaconda
 <span class="nv">$ </span>conda <span class="nb">install</span> <span class="nt">-c</span> fastai <span class="nt">-c</span> pytorch <span class="nt">-c</span> anaconda fastai gh anaconda <span class="nv">cudatoolkit</span><span class="o">=</span>10.2
 Collecting package metadata <span class="o">(</span>current_repodata.json<span class="o">)</span>: <span class="k">done
 </span>Solving environment: <span class="k">done</span>

 <span class="c">## Package Plan ##</span>

   environment location: /home/tbeck/anaconda3

   added / updated specs:
     - anaconda
     - <span class="nv">cudatoolkit</span><span class="o">=</span>10.2
     - fastai
     - gh


 The following packages will be downloaded:

     package                    |            build
     <span class="nt">---------------------------</span>|-----------------
     ca-certificates-2020.7.22  |                0         132 KB  anaconda
     certifi-2020.6.20          |           py37_0         159 KB  anaconda
     conda-4.8.4                |           py37_0         3.0 MB  anaconda
     cudatoolkit-10.2.89        |       hfd86e86_1       540.0 MB  anaconda
     gh-0.11.1                  |                0         5.5 MB  fastai
     openssl-1.1.1g             |       h7b6447c_0         3.8 MB  anaconda
     <span class="nt">------------------------------------------------------------</span>
                                           Total:       552.5 MB

 The following NEW packages will be INSTALLED:

   gh                 fastai/linux-64::gh-0.11.1-0

 The following packages will be SUPERSEDED by a higher-priority channel:

   ca-certificates                                 pkgs/main <span class="nt">--</span><span class="o">&gt;</span> anaconda
   certifi                                         pkgs/main <span class="nt">--</span><span class="o">&gt;</span> anaconda
   conda                                           pkgs/main <span class="nt">--</span><span class="o">&gt;</span> anaconda
   cudatoolkit                                     pkgs/main <span class="nt">--</span><span class="o">&gt;</span> anaconda
   openssl                                         pkgs/main <span class="nt">--</span><span class="o">&gt;</span> anaconda


 Proceed <span class="o">([</span>y]/n<span class="o">)</span>?
</code></pre></div>    </div>
  </li>
  <li>
    <p>Once installed, you can quickly test that your GPU is seen and used from the command line like so:</p>

    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code> <span class="nv">$ </span>python <span class="nt">-c</span> <span class="s1">'import torch; print(torch.cuda.get_device_name())'</span>
 GeForce GTX 970
 <span class="nv">$ </span>python <span class="nt">-c</span> <span class="s1">'import torch; print(torch.rand(2,3).cuda())'</span>
 tensor<span class="o">([[</span>0.3352, 0.0835, 0.5349],
         <span class="o">[</span>0.3712, 0.2851, 0.8767]], <span class="nv">device</span><span class="o">=</span><span class="s1">'cuda:0'</span><span class="o">)</span>
</code></pre></div>    </div>
  </li>
</ol>

<p>If you see your expected video card and a <code class="language-plaintext highlighter-rouge">tensor</code> returned, you’re all set. If you have multiple GPU’s installed, you may need to specify which one to use. Check out <a href="https://stackoverflow.com/questions/37893755/tensorflow-set-cuda-visible-devices-within-jupyter">this stack overflow article</a> on how to set the appropriate environment variables for the command line and for jupyter to work.</p>

<h3 id="a-note-on-updates">
<a class="anchor" href="#a-note-on-updates" aria-hidden="true"><span class="octicon octicon-link"></span></a>A note on updates</h3>

<p>I’ve noticed that if you update conda using <code class="language-plaintext highlighter-rouge">conda update --all</code>, it will try to pull in the latest version of <code class="language-plaintext highlighter-rouge">cudatoolkit</code>, which as of this writing is <code class="language-plaintext highlighter-rouge">cudatoolkit-11.0.221-h6bb024c_0</code>. This is safe to do, but you will need to downgrade back to <code class="language-plaintext highlighter-rouge">cudatoolkit-10.2</code>. This seems to be due to how anaconda handles/prioritizes packages from various channels. Below is an example.</p>

<h4 id="upgrading-conda-only-showing-cudatoolkit-for-visbility---your-output-will-differ">
<a class="anchor" href="#upgrading-conda-only-showing-cudatoolkit-for-visbility---your-output-will-differ" aria-hidden="true"><span class="octicon octicon-link"></span></a>Upgrading conda (only showing cudatoolkit for visbility - your output will differ)</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>conda update <span class="nt">--all</span>
...
The following packages will be UPDATED:

  cudatoolkit        anaconda::cudatoolkit-10.2.89-hfd86e8~ <span class="nt">--</span><span class="o">&gt;</span> pkgs/main::cudatoolkit-11.0.221-h6bb024c_0
</code></pre></div></div>

<h4 id="downgrading-cudatoolkit">
<a class="anchor" href="#downgrading-cudatoolkit" aria-hidden="true"><span class="octicon octicon-link"></span></a>Downgrading cudatoolkit</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>conda <span class="nb">install </span>pytorch torchvision <span class="nv">cudatoolkit</span><span class="o">=</span>10.2 <span class="nt">-c</span> pytorch
...
  added / updated specs:
    - <span class="nv">cudatoolkit</span><span class="o">=</span>10.2

The following packages will be downloaded:

    package                    |            build
    <span class="nt">---------------------------</span>|-----------------
    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB
    <span class="nt">------------------------------------------------------------</span>
                                           Total:       365.1 MB

The following packages will be DOWNGRADED:

  cudatoolkit                           11.0.221-h6bb024c_0 <span class="nt">--</span><span class="o">&gt;</span> 10.2.89-hfd86e86_1
</code></pre></div></div>

<h4 id="troubleshooting">
<a class="anchor" href="#troubleshooting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Troubleshooting</h4>

<p>If you get the below trying to use <code class="language-plaintext highlighter-rouge">torch</code> then cuda isn’t working as expected.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>python <span class="nt">-c</span> <span class="s1">'import torch; print(torch.rand(2,3).cuda())'</span>
Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
  File <span class="s2">"&lt;string&gt;"</span>, line 1, <span class="k">in</span> &lt;module&gt;
  File <span class="s2">"/home/tbeck/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/cuda/__init__.py"</span>, line 192, <span class="k">in </span>_lazy_init
    _check_driver<span class="o">()</span>
  File <span class="s2">"/home/tbeck/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/cuda/__init__.py"</span>, line 95, <span class="k">in </span>_check_driver
    raise AssertionError<span class="o">(</span><span class="s2">"Torch not compiled with CUDA enabled"</span><span class="o">)</span>
AssertionError: Torch not compiled with CUDA enabled
</code></pre></div></div>

<p>Note that trying to install <code class="language-plaintext highlighter-rouge">cudatoolkit=10.2</code> alone might result in this error, so be sure that <code class="language-plaintext highlighter-rouge">pytorch</code> and <code class="language-plaintext highlighter-rouge">torchvision</code> are included when specifying <code class="language-plaintext highlighter-rouge">cudatoolkit=10.2</code>.</p>

<h3 id="preparing-for-class">
<a class="anchor" href="#preparing-for-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparing for class</h3>

<p>There are two sets of notebooks for the class:</p>

<ul>
  <li>The <code class="language-plaintext highlighter-rouge">fastbook</code>, a guided set of notebooks with prose for following along in the videos: <a href="https://github.com/fastai/fastbook">fastbook</a>
</li>
  <li>The same notebooks as a study aid: <a href="https://github.com/fastai/course-v4">course-v4</a>
</li>
</ul>

<p>Please consider showing your support by buying the fastbook: <a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD</a></p>

<p>I setup my own area for hacking:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir</span> ~/src
<span class="nv">$ </span><span class="nb">cd</span> ~/src <span class="o">&amp;&amp;</span> git clone https://github.com/fastai/fastbook.git <span class="o">&amp;&amp;</span> git clone https://github.com/fastai/course-v4.git
</code></pre></div></div>

<p>Now that CUDA is working and we have the code, I prefer fire up my <code class="language-plaintext highlighter-rouge">jupyter notebook</code> in a <code class="language-plaintext highlighter-rouge">screen</code> session. To do this I generated a <a href="default%20jupyter%20notebook%20config">https://jupyter-notebook.readthedocs.io/en/stable/config.html</a> via <code class="language-plaintext highlighter-rouge">jupyte notebook --generate-config</code> and wrote it to <code class="language-plaintext highlighter-rouge">~/.jupyter/jupyte_notebook_config.py</code>. Then I made it listen on <code class="language-plaintext highlighter-rouge">0.0.0.0</code> so I can reach it from my LAN (or anywhere in the world via wireguard!).</p>

<p>Now I just run <code class="language-plaintext highlighter-rouge">screen</code>, activate conda with <code class="language-plaintext highlighter-rouge">conda activate fastai</code>, and finally start jupyter with <code class="language-plaintext highlighter-rouge">jupyter notebook</code>. For tricks on using screen see <a href="https://gist.github.com/jctosta/af918e1618682638aa82">this quickreference</a></p>

<p>If you prefer to use jupyter lab, you’ll need to <code class="language-plaintext highlighter-rouge">conda install jupyterlab</code> and run <code class="language-plaintext highlighter-rouge">jupyter lab</code> instead.</p>

  </div><a class="u-url" href="/education/fastai/2020/09/05/the-story-so-far.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Blogging my experiences learning ML via the fast.ai courses.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/tmbeck" title="tmbeck"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
